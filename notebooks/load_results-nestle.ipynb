{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DirectDmTargets as dddm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multihist as mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "# import numpy as np\n",
    "import scipy.optimize\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000000)\n",
    "pd.set_option('display.max_columns', 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading normal results.\n",
    "results = {}\n",
    "for i in range(400):\n",
    "    try:\n",
    "        results[i] = dddm.load_nestle_samples(\n",
    "            \"../../results/nestle\", i)\n",
    "        print()\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in results.keys():\n",
    "# for key in selected_keys:\n",
    "    print(f\"---{key}---\")\n",
    "    result = results[key]\n",
    "    try:\n",
    "        print('earth_shielding',result['config']['earth_shielding'])\n",
    "#         if result['config']['earth_shielding'] == False:\n",
    "#             print(result['config']['notes'])\n",
    "#             pass\n",
    "        dddm.nestle_corner(result, save = f\"../results/nestle{key}/\")\n",
    "    except KeyError:\n",
    "        pass\n",
    "#     dddm.nestle_corner(result, save = f\"../results/nestle{key}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def results_to_df(res):\n",
    "    df = pd.DataFrame()\n",
    "    items = sorted(list(res.keys()))\n",
    "    df['item'] = items\n",
    "    for key in res[np.min(list(res.keys()))].keys():\n",
    "        if key in ['samples', 'weights']:\n",
    "            continue\n",
    "        if key == 'config' or key == 'res_dict':\n",
    "            for sub_key in res[items[0]][key].keys():\n",
    "                if sub_key == 'prior':\n",
    "                    for sub_sub_key in res[items[0]][key][sub_key].keys():\n",
    "                        if type(res[items[0]][key][sub_key][sub_sub_key]) == dict:\n",
    "                            for sub_sub_sub_key in res[items[0]][key][sub_key][sub_sub_key].keys():\n",
    "                                df[key+'_'+sub_key+'_'+sub_sub_key+'_'+sub_sub_sub_key] = [res[it][key][sub_key][sub_sub_key][sub_sub_sub_key] for it in items]\n",
    "                        else:\n",
    "                            df[key+'_'+sub_key+'_'+sub_sub_key] = [res[it][key][sub_key][sub_sub_key] for it in items]\n",
    "                else:\n",
    "                    df[key+'_'+sub_key] = [res[it][key][sub_key] for it in items]\n",
    "            \n",
    "        else:\n",
    "            df[key] = [res[it][key] for it in items]\n",
    "        \n",
    "            \n",
    "    df['mw'] = 10 ** df['config_mw']\n",
    "    df['n_fit_parameters'] = [len(pars) for pars in df['config_fit_parameters']]\n",
    "    return df\n",
    "df = results_to_df(results)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['config_detector'] == 'Xe_migd'\n",
    "mask2= df[mask]['res_dict_nestle_nposterior'] > 2000\n",
    "selection = df[mask][mask2]['item'].values\n",
    "df[mask][mask2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cols = ['config_detector','mw', 'n_fit_parameters', 'res_dict_mass_fit_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask = (\n",
    "    (df['config_prior_density_mean'] == 0.40) & \n",
    "    (df['config_sigma'] == -45) \n",
    "    & (df['mw'] < 51)\n",
    "#    & (df['mw'] < 51) & (df['mw'] > 49)\n",
    "#    & (df['mw'] < 26) & (df['mw'] > 24)\n",
    "#     (len(df['config_fit_parameters']) == 2)\n",
    ")\n",
    "df_sel =df[mask]\n",
    "values = np.array([np.float(val.split('+/-')[0]) for val in df_sel['res_dict_mass_fit_res']])\n",
    "errors = np.array([np.float(val.split('+/-')[1]) for val in df_sel['res_dict_mass_fit_res']])\n",
    "\n",
    "df_sel['dmw_[%]'] = errors/values * 100 \n",
    "if 'dmw_[%]' not in summary_cols:\n",
    "    summary_cols += ['dmw_[%]']\n",
    "res = {}\n",
    "for sel in np.unique(df_sel['config_notes']):\n",
    "    print(sel)\n",
    "    sub_sel = df['config_notes'] == sel\n",
    "    res[sel]=df_sel[sub_sel][summary_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel[summary_cols].sort_values(['config_detector','mw'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]['config']['prior']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]['res_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = 'Ar'\n",
    "mask = df['config_detector'] == det\n",
    "sets = np.unique(df[mask]['config_notes'].values)\n",
    "assert len(sets) == 2, \"you have to manually select the keys since there are multiple sets in the query\"\n",
    "selected_keys_sets = [df[df['config_notes'] == _set]['item'].values for _set in sets] \n",
    "selected_keys_names = [\"benchmark SHM constrained fit\",\n",
    "                      \"benchmark SHM astr. unconstraint fit\",\n",
    "#                       \"updated SHM constrained fit\",\n",
    "#                       \"updated SHM astr. unconstraint fit\"\n",
    "                      ]\n",
    "selected_keys_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def results_to_df(res):\n",
    "#     df = pd.DataFrame()\n",
    "#     items = sorted(list(res.keys()))\n",
    "# #     df['item'] = np.arange(len(items))\n",
    "#     for key_i, key in enumerate(items):\n",
    "#         for subkey in res[key].keys():\n",
    "#             print(key_i, key, subkey, res[key][subkey])\n",
    "#             try: df.loc(key_i)[subkey] = res[key][subkey]\n",
    "#             except:\n",
    "#                 return df\n",
    "# #         if key in ['samples', 'weights']:\n",
    "# #             continue\n",
    "# #         if True:\n",
    "# #             for sub_key in res[items[0]][key].keys():\n",
    "# # #                 if sub_key == 'prior':\n",
    "# # #                     for sub_sub_key in res[items[0]][key][sub_key].keys():\n",
    "# # #                         if type(res[items[0]][key][sub_key][sub_sub_key]) == dict:\n",
    "# # #                             for sub_sub_sub_key in res[items[0]][key][sub_key][sub_sub_key].keys():\n",
    "# # #                                 df[key+'_'+sub_key+'_'+sub_sub_key+'_'+sub_sub_sub_key] = [res[it][key][sub_key][sub_sub_key][sub_sub_sub_key] for it in items]\n",
    "# # #                         else:\n",
    "# # #                             df[key+'_'+sub_key+'_'+sub_sub_key] = [res[it][key][sub_key][sub_sub_key] for it in items]\n",
    "# # #                 else:\n",
    "# #                     df[key+'_'+sub_key] = [res[it][key][sub_key] for it in items]\n",
    "            \n",
    "# # #         else:\n",
    "# #         df[key] = [res[it][key] for it in items]\n",
    "        \n",
    "            \n",
    "#     df['mw'] = 10 ** df['config_mw']\n",
    "#     df['n_fit_parameters'] = [len(pars) for pars in df['config_fit_parameters']]\n",
    "#     return df\n",
    "# test = results_to_df(dddm.convert_dic_to_savable(dddm.experiment))\n",
    "# test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for key in results.keys():\n",
    "# # for key in selected_keys:\n",
    "#     print(f\"---{key}---\")\n",
    "#     result = results[key]\n",
    "#     dddm.nestle_corner(result, save = f\"../results/nestle_17nov{key}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior(samples, weights):\n",
    "    # re-scale weights to have a maximum of one\n",
    "    nweights = weights/np.max(weights)\n",
    "\n",
    "    # get the probability of keeping a sample from the weights\n",
    "    keepidx = np.where(np.random.rand(len(nweights)) < nweights)[0]\n",
    "    # get the posterior samples\n",
    "    return samples[keepidx,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_center(xedges, yedges):\n",
    "    return 0.5 * (xedges[0:-1] + xedges[1:]), 0.5 * (yedges[0:-1] + yedges[1:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(item, nbins = 45):\n",
    "#     nbins = 45\n",
    "    bin_range = [[1, 3], [-46, -44]]\n",
    "    counts, xedges, yedges = np.histogram2d(*get_p_i(item), bins = nbins, range = bin_range)\n",
    "    return counts , xedges, yedges\n",
    "\n",
    "def get_hist_norm(item):\n",
    "    counts , xedges, yedges = get_hist(item)\n",
    "    return counts/np.sum(counts) , xedges, yedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fig = plt.figure(figsize=(7, 3))\n",
    "# # ax = fig.add_subplot(131, title='imshow: square bins')\n",
    "# from matplotlib.colors import LogNorm\n",
    "# plt.imshow(test.T/np.sum(test.T), interpolation='nearest', origin='low',\n",
    "#         extent=  [1, 3, -45.7, -44.3], norm=LogNorm())\n",
    "# # plt.legend()\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_i(i):\n",
    "    m, sig = get_posterior(results[i]['samples'], results[i]['weights']).T[:2]\n",
    "    return np.array([m, sig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "def combine_normalized(items):\n",
    "    X, Y = np.meshgrid(*get_hist_norm(items[0])[1:])\n",
    "    for i in items:\n",
    "        c,_,_ = get_hist_norm(i)\n",
    "        im = plt.pcolor(X,Y,c.T, norm=LogNorm(vmin = 1e-4,vmax = 1))  \n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow10(x):\n",
    "    return 10 ** x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def confidence_plot(items, text_box = False):\n",
    "    fig,ax=plt.subplots(figsize = (8,6))\n",
    "    for k, item in enumerate(items):#, 78, 110 \n",
    "        x,y =get_p_i(item)\n",
    "        # Make a 2d normed histogram\n",
    "        bin_range = [[0.5, 3], [-45.7, -44.3]]\n",
    "        H,xedges,yedges=np.histogram2d(x,y,bins=500, range = bin_range, normed=True)\n",
    "\n",
    "        norm=H.sum() # Find the norm of the sum\n",
    "        # Set contour levels\n",
    "        contour1=0.99\n",
    "        contour2=0.95\n",
    "        contour3=0.68\n",
    "        # Take histogram bin membership as proportional to Likelihood\n",
    "        # This is true when data comes from a Markovian process\n",
    "        def objective(limit, target):\n",
    "            w = np.where(H>limit)\n",
    "            count = H[w]\n",
    "            return count.sum() - target\n",
    "        target1 = norm*contour1\n",
    "        target2 = norm*contour2\n",
    "        target3 = norm*contour3\n",
    "\n",
    "        # Find levels by summing histogram to objective\n",
    "        level1= scipy.optimize.bisect(objective, H.min(), H.max(), args=(target1,))\n",
    "        level2= scipy.optimize.bisect(objective, H.min(), H.max(), args=(target2,))\n",
    "        level3= scipy.optimize.bisect(objective, H.min(), H.max(), args=(target3,))\n",
    "\n",
    "        levels=[level1, level2, level3,H.max()]\n",
    "        # Pass levels to normed kde plot\n",
    "        def av_levels(x):\n",
    "            return [(x[i] + x[i+1])/2 for i in range(len(x)-1)]\n",
    "\n",
    "        if levels[0]==levels[1]:\n",
    "            print(\"ERRRRRRRRR\\n\\n\")\n",
    "            print(levels)\n",
    "            levels[0] /= 1.01\n",
    "            levels = np.unique(levels)\n",
    "            print(levels)\n",
    "        sns_ax = sns.kdeplot(x,y, shade=True,ax=ax,n_levels=levels,cmap=\"viridis\",normed=True, \n",
    "                    cbar = False, vmin=levels[0], vmax=levels[-1])\n",
    "        kwargs = {}\n",
    "        if k is 0:\n",
    "            kwargs['label'] = 'best fit'\n",
    "        plt.scatter(np.mean(x),np.mean(y), c='black',\n",
    "                    marker = '+',**kwargs)\n",
    "        if k is 0:\n",
    "            kwargs['label'] = 'benchmark value'\n",
    "        plt.scatter(results[item]['config']['mw'],\n",
    "                    results[item]['config']['sigma'], c='blue',\n",
    "                    marker = 'x',\n",
    "                    **kwargs)\n",
    "        if k is 0:\n",
    "            cbar = ax.figure.colorbar(sns_ax.collections[0])\n",
    "            cbar.set_ticks(av_levels(np.linspace(0,1,4)))\n",
    "            cbar.set_ticklabels(['$3\\sigma$', '$2\\sigma$', '$1\\sigma$'])\n",
    "            cbar.set_label(\"Posterior probability\")\n",
    "    secax = ax.secondary_xaxis('top', functions=(pow10, np.log10))\n",
    "    x_ticks = [15, 25, 50, 100, 250, 500, 1000]\n",
    "    for x_tick in x_ticks:\n",
    "        ax.axvline(np.log10(x_tick), alpha = 0.1)\n",
    "    secax.set_ticks(x_ticks)\n",
    "    plt.xlim(np.log10(x_ticks[0]),np.log10(x_ticks[-1]))\n",
    "    plt.xlabel(\"$\\log_{10}(M_{\\chi}$ $[GeV/c^{2}]$)\")\n",
    "    secax.set_xlabel(\"$M_{\\chi}$ $[GeV/c^{2}]$\")\n",
    "    plt.ylabel(\"$\\log_{10}(\\sigma_{S.I.}$ $[cm^{2}]$)\")\n",
    "    plt.legend()\n",
    "\n",
    "    if text_box:\n",
    "        plt.text(0.05, 0.95, text_box, \n",
    "                 bbox=dict(facecolor=\"white\",\n",
    "                           boxstyle=\"round\"), \n",
    "                 transform=ax.transAxes,\n",
    "                 alpha=0.5)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = 'Xe_migd'\n",
    "for i in selection:\n",
    "    confidence_plot([results[i], text_box = f'{det}-detector')\n",
    "#     if \"realistic\" in name:\n",
    "#     plt.ylim(-49, -45)\n",
    "#     else:\n",
    "    plt.ylim(-45.7, -44.3)\n",
    "    plt.title(f'{name} \\n')\n",
    "    plt.savefig(f\"figures/{det}_{name.replace(' ', '-')}.png\", dpi =300, bbox_inches=\"tight\")\n",
    "    plt.savefig(f\"figures/{det}_{name.replace(' ', '-')}.pdf\", dpi =300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "                \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, name in enumerate(selected_keys_names):\n",
    "    confidence_plot(selected_keys_sets[i], text_box = f'{det}-detector')\n",
    "#     if \"realistic\" in name:\n",
    "#     plt.ylim(-49, -45)\n",
    "#     else:\n",
    "    plt.ylim(-45.7, -44.3)\n",
    "    plt.title(f'{name} \\n')\n",
    "    plt.savefig(f\"figures/{det}_{name.replace(' ', '-')}.png\", dpi =300, bbox_inches=\"tight\")\n",
    "    plt.savefig(f\"figures/{det}_{name.replace(' ', '-')}.pdf\", dpi =300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "                \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = 'Ge'\n",
    "mask = df['config_detector'] == det\n",
    "sets = np.unique(df[mask]['config_notes'].values)\n",
    "assert len(sets) == 2, \"you have to manually select the keys since there are multiple sets in the query\"\n",
    "selected_keys_sets = [df[df['config_notes'] == _set]['item'].values for _set in sets] \n",
    "selected_keys_names = [\"benchmark SHM constrained fit\",\n",
    "                      \"benchmark SHM astr. unconstraint fit\",\n",
    "#                       \"updated SHM constrained fit\",\n",
    "#                       \"updated SHM astr. unconstraint fit\"\n",
    "                      ]\n",
    "selected_keys_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(selected_keys_names):\n",
    "    confidence_plot(selected_keys_sets[i], text_box = f'{det}-detector')\n",
    "    if \"realistic\" in name:\n",
    "        plt.ylim(-49, -45)\n",
    "    else:\n",
    "        plt.ylim(-45.7, -44.3)\n",
    "    plt.title(f'{name} \\n')\n",
    "    plt.savefig(f\"figures/{det}_{name.replace(' ', '-')}.png\", dpi =300, bbox_inches=\"tight\")\n",
    "    plt.savefig(f\"figures/{det}_{name.replace(' ', '-')}.pdf\", dpi =300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = 'Xe'\n",
    "mask = df['config_detector'] == det\n",
    "sets = np.unique(df[mask]['config_notes'].values)\n",
    "assert len(sets) == 2, \"you have to manually select the keys since there are multiple sets in the query\"\n",
    "selected_keys_sets = [df[df['config_notes'] == _set]['item'].values for _set in sets] \n",
    "selected_keys_names = [\"benchmark SHM constrained fit\",\n",
    "                      \"benchmark SHM astr. unconstraint fit\",\n",
    "#                       \"updated SHM constrained fit\",\n",
    "#                       \"updated SHM astr. unconstraint fit\"\n",
    "                      ]\n",
    "selected_keys_sets\n",
    "\n",
    "for i, name in enumerate(selected_keys_names):\n",
    "    confidence_plot(selected_keys_sets[i], text_box = f'{det}-detector')\n",
    "    if \"realistic\" in name:\n",
    "        plt.ylim(-49, -45)\n",
    "    else:\n",
    "        plt.ylim(-45.7, -44.3)\n",
    "    plt.title(f'{name} \\n')\n",
    "    plt.savefig(f\"figures/{det}_{name.replace(' ', '-')}.png\", dpi =300, bbox_inches=\"tight\")\n",
    "    plt.savefig(f\"figures/{det}_{name.replace(' ', '-')}.pdf\", dpi =300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantile(item):\n",
    "    _, xedges, _ = get_hist(item, nbins = 1000)\n",
    "    data = get_p_i(item)\n",
    "    results = np.zeros((len(xedges),3))\n",
    "#     print(results)\n",
    "    for i in range(len(xedges) - 1):\n",
    "#         print(bin_i)\n",
    "        mask = (xedges[i] < data[0]) & (data[0] < xedges[i+1])\n",
    "        if np.sum(mask)>0:\n",
    "#             print()\n",
    "            results[i] =  0.5 * (xedges[i]+ xedges[i+1]), *np.percentile(data[1][mask], [5,95])\n",
    "    return results[results[:,0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = get_quantile(0)\n",
    "# quantiles = quantiles[quantiles]\n",
    "plt.plot(quantiles[:,0],quantiles[:,1])\n",
    "plt.plot(quantiles[:,0],quantiles[:,2])\n",
    "# quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = get_hist(0)[0]\n",
    "centers = bin_center(*get_hist(0)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in counts.T:\n",
    "    print(np.percentile(count, [5, 95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_normalized([0])\n",
    "quantiles = get_quantile(0)\n",
    "# quantiles = quantiles[quantiles]\n",
    "plt.plot(quantiles[:,0],quantiles[:,1])\n",
    "plt.plot(quantiles[:,0],quantiles[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(get_p_i(0)[:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_p_i(0)\n",
    "np.array(test)[:,:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_plot(selected_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.optimize\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Generate some random data\n",
    "# # x,y=np.random.randn(2,100000)\n",
    "# fig,ax=plt.subplots(figsize = (8,6))\n",
    "# for k, item in enumerate([74, 78, 110]):#, 78, 110 \n",
    "#     x,y =get_p_i(item)\n",
    "#     # Make a 2d normed histogram\n",
    "#     H,xedges,yedges=np.histogram2d(x,y,bins=40,normed=True)\n",
    "\n",
    "#     norm=H.sum() # Find the norm of the sum\n",
    "#     # Set contour levels\n",
    "#     contour1=0.99\n",
    "#     contour2=0.95\n",
    "#     contour3=0.68\n",
    "#     # Take histogram bin membership as proportional to Likelihood\n",
    "#     # This is true when data comes from a Markovian process\n",
    "#     def objective(limit, target):\n",
    "#         w = np.where(H>limit)\n",
    "#         count = H[w]\n",
    "#         return count.sum() - target\n",
    "# #     contour={}\n",
    "# #     target={}\n",
    "# #     level={}\n",
    "# #     sigmas = np.flip(range(2,4))\n",
    "# #     for s in sigmas:\n",
    "# #         contour[s] = sigma_to_p(s)\n",
    "# #         print(contour[s])\n",
    "# #         target[s]=norm*contour[s]\n",
    "# #         level[s]=scipy.optimize.bisect(objective, H.min(), H.max(), args=(target[s],))\n",
    "# #     # Set target levels as percentage of norm\n",
    "#     target1 = norm*contour1\n",
    "#     target2 = norm*contour2\n",
    "#     target3 = norm*contour3\n",
    "\n",
    "\n",
    "\n",
    "#     # Find levels by summing histogram to objective\n",
    "#     level1= scipy.optimize.bisect(objective, H.min(), H.max(), args=(target1,))\n",
    "#     level2= scipy.optimize.bisect(objective, H.min(), H.max(), args=(target2,))\n",
    "#     level3= scipy.optimize.bisect(objective, H.min(), H.max(), args=(target3,))\n",
    "\n",
    "#     # For nice contour shading with seaborn, define top level\n",
    "# #     level[s+1]=H.max()\n",
    "# #     levels=[level[s] for s in sigmas]\n",
    "# #     levels.append(H.max())\n",
    "#     levels=[level1, level2, level3,H.max()]\n",
    "#     print(levels)\n",
    "#     # Pass levels to normed kde plot\n",
    "#     def av_levels(x):\n",
    "#         return [(x[i] + x[i+1])/2 for i in range(len(x)-1)]\n",
    "    \n",
    "# #     sns_ax = sns.kdeplot(x,y, shade=True,ax=ax,n_levels=levels,cmap=\"viridis\",normed=True, \n",
    "# #                 cbar = True, vmin=levels[0], vmax=levels[-1], \n",
    "# #                          cbar_kws={#\"ticklocation\":av_levels(levels),\n",
    "# #                                    \"ticks\":[],\n",
    "# #                                    #\"format\":\">%s<\"\n",
    "# # #                                    \"format\":av_levels(levels)\n",
    "# # #                                   \"ticks\":[1,3,4]\n",
    "# #                                    \"label\":\"significance\"\n",
    "# #                                   })\n",
    "    \n",
    "#     if levels[0]==levels[1]:\n",
    "#         print(\"ERRRRRRRRR\\n\\n\")\n",
    "#         levels[0] /= 1.01\n",
    "#     sns_ax = sns.kdeplot(x,y, shade=True,ax=ax,n_levels=levels,cmap=\"viridis\",normed=True, \n",
    "#                 cbar = False, vmin=levels[0], vmax=levels[-1])\n",
    "# #                          cbar_kws={#\"ticklocation\":av_levels(levels),\n",
    "# #                                    \"ticks\":[],\n",
    "# #                                    #\"format\":\">%s<\"\n",
    "# # #                                    \"format\":av_levels(levels)\n",
    "# # #                                   \"ticks\":[1,3,4]\n",
    "# #                                    \"label\":\"significance\"\n",
    "# #                                   })\n",
    "#                             #          \"labels\":levels})\n",
    "# #     fig.colorbar(cax,ticks=[-1, 0, 1])\n",
    "# #     ax.set_aspect('equal')\n",
    "#     kwargs = {}\n",
    "#     if k is 0:\n",
    "#         kwargs['label'] = 'best fit'\n",
    "#     plt.scatter(np.mean(x),np.mean(y), c='black',\n",
    "#                 marker = '+',**kwargs)\n",
    "#     if k is 0:\n",
    "#         kwargs['label'] = 'benchmark value'\n",
    "#     plt.scatter(results[item]['config']['mw'],\n",
    "#                 results[item]['config']['sigma'], c='blue',\n",
    "#                 marker = 'x',\n",
    "#                 **kwargs)\n",
    "#     if k is 0:\n",
    "#         cbar = ax.figure.colorbar(sns_ax.collections[0])\n",
    "#     #     cbar = sns_ax.figure.colorbar()#[0].colorbar\n",
    "#     #     print(av_levels(levels))\n",
    "#     #     cbar.set_ticks(av_levels(levels))\n",
    "#         cbar.set_ticks(av_levels(np.linspace(0,1,4)))\n",
    "#     #     print(level1)\n",
    "#         cbar.set_ticklabels(['$3\\sigma$', '$2\\sigma$', '$1\\sigma$'])\n",
    "#         cbar.set_label(\"Confidence interval\")\n",
    "#     #     cbar.set_nbins(4)\n",
    "# secax = ax.secondary_xaxis('top', functions=(pow10, np.log10))\n",
    "# # ax1.set_xticklabels([1])\n",
    "# # ax.set_xlim(np.log10(10),np.log10(1000))\n",
    "# x_ticks = [15, 25, 50, 100, 250, 500, 1000]\n",
    "# for x_tick in x_ticks:\n",
    "#     ax.axvline(np.log10(x_tick), alpha = 0.1)\n",
    "# secax.set_ticks(x_ticks)\n",
    "# plt.xlim(np.log10(x_ticks[0]),np.log10(x_ticks[-1]))\n",
    "# plt.xlabel(\"$\\log_{10}(M_{\\chi}$ $[GeV/c^{2}]$)\")\n",
    "# secax.set_xlabel(\"$M_{\\chi}$ $[GeV/c^{2}]$\")\n",
    "# plt.ylabel(\"$\\log_{10}(\\sigma_{S.I.}$ $[cm^{2}]$)\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "def sigma_to_p(x):\n",
    "    return erf(x/np.sqrt(2))\n",
    "\n",
    "for x in range(1,5):\n",
    "    print(x, sigma_to_p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_normalized(selection[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_normalized(selected_keys_sets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(np.linspace(0,100,100), [5,95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = selected_keys[:3]\n",
    "def get_df(items):\n",
    "#     df = pd.DataFrame()\n",
    "    for j, item in enumerate(items):\n",
    "        posteriors = get_p_i(item)\n",
    "        test_df = pd.DataFrame()\n",
    "        \n",
    "        test_df['$\\log(M_\\chi)$'] = posteriors[0]\n",
    "        test_df['$\\log(\\sigma)$'] = posteriors[1]\n",
    "        test_df['mass'] = 10**results[item]['config']['mw']\n",
    "#         sns.jointplot(x=\"x\", y=\"y\", data=test_df, kind=\"kde\",\n",
    "#                      ylim = [-46,-44],\n",
    "#                      xlim = [1,3]);\n",
    "        if j == 0:\n",
    "            df = test_df\n",
    "        else:\n",
    "            df = pd.concat([df, test_df])\n",
    "#     df = df.assign(industry='yyy')\n",
    "    return df\n",
    "data = get_df(items)\n",
    "print(np.unique(data.mass), len(data))\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_set(items, save_as):\n",
    "    # data = sns.load_dataset('iris')\n",
    "    # plt.figure(figsize=(15,10))\n",
    "    data = get_df(items)\n",
    "    print(np.unique(data.mass), len(data))\n",
    "    def make_kde(*args, **kwargs):  \n",
    "        #\"cbar\":True, \n",
    "    #     opts ={\"n_levels\":5}\n",
    "        sns.kdeplot(n_levels = 3, *args, cmap=next(make_kde.cmap_cycle), **kwargs)\n",
    "\n",
    "    def make_kde_cbar(*args, **kwargs):  \n",
    "        #\"cbar\":True, \n",
    "    #     opts ={\"n_levels\":5}\n",
    "        sns.kdeplot(n_levels = 3, cbar = True, *args, cmap=next(make_kde.cmap_cycle), **kwargs)\n",
    "    kwargs ={\"cbar\":True, \"n_levels\":5}\n",
    "    make_kde.cmap_cycle = cycle(('Blues_r', 'Oranges_r', 'Greens_r'))\n",
    "\n",
    "    pg = sns.PairGrid(data, vars=('$\\log(M_\\chi)$', '$\\log(\\sigma)$'), hue='mass')\n",
    "    pg.map_diag(sns.kdeplot)#, color = ({)'b', 'g', 'r'})\n",
    "    pg.map_lower(make_kde)\n",
    "    # pg.map_upper(make_kde_cbar)\n",
    "    pg.fig.set_size_inches(15,10)\n",
    "    pg.fig.savefig(f\"{det}_{save_as}.png\", dpi =300)\n",
    "    pg.fig.savefig(f\"{det}_{save_as}.pdf\", dpi =300)\n",
    "    plt.title(f\"{save_as}\")\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(selected_keys_names)):\n",
    "    plot_set(selected_keys_sets[k], selected_keys_names[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items = selected_keys[:3]\n",
    "def get_df(items):\n",
    "#     df = pd.DataFrame()\n",
    "    for j, item in enumerate(items):\n",
    "        posteriors = get_p_i(item)\n",
    "        test_df = pd.DataFrame()\n",
    "        \n",
    "        test_df['$\\log(M_\\chi)$'] = posteriors[0]\n",
    "        test_df['$\\log(\\sigma)$'] = posteriors[1]\n",
    "        test_df['mass'] = 10**results[item]['config']['mw']\n",
    "#         sns.jointplot(x=\"x\", y=\"y\", data=test_df, kind=\"kde\",\n",
    "#                      ylim = [-46,-44],\n",
    "#                      xlim = [1,3]);\n",
    "        if j == 0:\n",
    "            df = test_df\n",
    "        else:\n",
    "            df = pd.concat([df, test_df])\n",
    "#     df = df.assign(industry='yyy')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = selected_keys_sets[0]\n",
    "data = get_df(items)\n",
    "print(np.unique(data.mass), len(data))\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# data = sns.load_dataset('iris')\n",
    "# plt.figure(figsize=(15,10))\n",
    "def make_kde(*args, **kwargs):  \n",
    "    #\"cbar\":True, \n",
    "#     opts ={\"n_levels\":5}\n",
    "    sns.kdeplot(n_levels = 3, *args, cmap=next(make_kde.cmap_cycle), **kwargs)\n",
    "\n",
    "def make_kde_cbar(*args, **kwargs):  \n",
    "    #\"cbar\":True, \n",
    "#     opts ={\"n_levels\":5}\n",
    "    sns.kdeplot(n_levels = 3, cbar = True, *args, cmap=next(make_kde.cmap_cycle), **kwargs)\n",
    "kwargs ={\"cbar\":True, \"n_levels\":5}\n",
    "make_kde.cmap_cycle = cycle(('Blues_r', 'Oranges_r', 'Greens_r'))\n",
    "\n",
    "pg = sns.PairGrid(data, vars=('$\\log(M_\\chi)$', '$\\log(\\sigma)$'), hue='mass')\n",
    "pg.map_diag(sns.kdeplot)#, color = ({)'b', 'g', 'r'})\n",
    "pg.map_lower(make_kde)\n",
    "# pg.map_upper(make_kde_cbar)\n",
    "pg.fig.set_size_inches(15,10)\n",
    "pg.fig.savefig(f\"{det}_fixed_astroph.png\", dpi =300)\n",
    "pg.fig.savefig(f\"{det}_fixed_astroph.pdf\", dpi =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = selected_keys_sets[0]\n",
    "data = get_df(items)\n",
    "print(np.unique(data.mass), len(data))\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# data = sns.load_dataset('iris')\n",
    "# plt.figure(figsize=(15,10))\n",
    "def make_kde(*args, **kwargs):  \n",
    "    #\"cbar\":True, \n",
    "#     opts ={\"n_levels\":5}\n",
    "    sns.kdeplot(n_levels = 3, *args, cmap=next(make_kde.cmap_cycle), **kwargs)\n",
    "\n",
    "def make_kde_cbar(*args, **kwargs):  \n",
    "    #\"cbar\":True, \n",
    "#     opts ={\"n_levels\":5}\n",
    "    sns.kdeplot(n_levels = 3, cbar = True, *args, cmap=next(make_kde.cmap_cycle), **kwargs)\n",
    "kwargs ={\"cbar\":True, \"n_levels\":5}\n",
    "make_kde.cmap_cycle = cycle(('Blues_r', 'Oranges_r', 'Greens_r'))\n",
    "\n",
    "pg = sns.PairGrid(data, vars=('$\\log(M_\\chi)$', '$\\log(\\sigma)$'), hue='mass')\n",
    "pg.map_diag(sns.kdeplot)#, color = ({)'b', 'g', 'r'})\n",
    "pg.map_lower(make_kde)\n",
    "# pg.map_upper(make_kde_cbar)\n",
    "pg.fig.set_size_inches(15,10)\n",
    "pg.fig.savefig(f\"{det}_loose_astroph.png\", dpi =300)\n",
    "pg.fig.savefig(f\"{det}_loose_astroph.pdf\", dpi =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(np.random.normal(1, 1, 10**6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import mquantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x, y = np.random.multivariate_normal(mean, cov, 1000).T\n",
    "with sns.axes_style(\"white\"):\n",
    "    sns.jointplot(x=test[0], y=test[1], kind=\"hex\", color=\"k\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.kdeplot(test[0], test[1], ax=ax)\n",
    "sns.rugplot(test[0], color=\"g\", ax=ax)\n",
    "sns.rugplot(test[1], vertical=True, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['x'] = test[0]\n",
    "test_df['y'] = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"x\", y=\"y\", data=test_df, kind=\"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = selected_keys\n",
    "\n",
    "def plot_posterior(items):\n",
    "    posteriors = [get_p_i(item) for item in items]\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    test_df['x'] = np.concatenate([p[0] for p in posteriors])\n",
    "    test_df['y'] = np.concatenate([p[1] for p in posteriors])\n",
    "    sns.jointplot(x=\"x\", y=\"y\", data=test_df, kind=\"kde\",\n",
    "                 ylim = [-46,-44],\n",
    "                 xlim = [1,3]);\n",
    "plot_posterior(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = selected_keys[:3]\n",
    "def plot_posterior_per_item(items):\n",
    "    for item in items:\n",
    "        posteriors = get_p_i(item)\n",
    "        test_df = pd.DataFrame()\n",
    "\n",
    "        test_df['x'] = posteriors[0]\n",
    "        test_df['y'] = posteriors[1]\n",
    "        sns.jointplot(x=\"x\", y=\"y\", data=test_df, kind=\"kde\",\n",
    "                     ylim = [-46,-44],\n",
    "                     xlim = [1,3]);\n",
    "plot_posterior_per_item(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items = selected_keys[:3]\n",
    "\n",
    "# # sns.jointplot(x=\"x\", y=\"y\", data=test_df, kind=\"kde\",\n",
    "# #                      ylim = [-46,-44],\n",
    "# #                      xlim = [1,3]);\n",
    "# def plot_posterior_per_item(items):\n",
    "#     for j, item in enumerate(items):\n",
    "#         posteriors = get_p_i(item)\n",
    "#         test_df = pd.DataFrame()\n",
    "\n",
    "#         test_df[f'x'] = posteriors[0]\n",
    "#         test_df[f'y'] = posteriors[1]\n",
    "#         if j ==0:\n",
    "            \n",
    "#             grid = sns.JointGrid(x=\"x\", y=\"y\", data=test_df)\n",
    "#         grid = grid.plot_joint(\n",
    "#             sns.jointplot(x=\"x\", y=\"y\", data=test_df, kind=\"kde\",\n",
    "#                      ylim = [-46,-44],\n",
    "#                      xlim = [1,3]));\n",
    "# plot_posterior_per_item(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time\n",
    "# items = results.keys()\n",
    "# def get_p_i(i):\n",
    "#     return get_posterior(results[i]['samples'], results[i]['weights']).T[:2]\n",
    "# posteriors = [get_p_i(item) for item in items]\n",
    "# test_df = pd.DataFrame()\n",
    "\n",
    "# test_df['x'] = np.concatenate([p[0] for p in posteriors])\n",
    "# test_df['y'] = np.concatenate([p[1] for p in posteriors])\n",
    "# sns.jointplot(x=\"x\", y=\"y\", data=test_df, kind=\"kde\",\n",
    "#              ylim = [-46,-44],\n",
    "#              xlim = [1,3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
